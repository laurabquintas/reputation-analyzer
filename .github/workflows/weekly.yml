name: Weekly Reputation Update

on:
  schedule:
    - cron: "0 6 * * 1" # Mondays 06:00 UTC
  workflow_dispatch:

jobs:
  test:
    runs-on: self-hosted
    permissions:
      contents: read
    steps:
      - uses: actions/checkout@v4

      - name: Show Python version on self-hosted runner
        run: python3 --version

      - name: Install deps
        run: |
          python3 -m pip install -U pip
          python3 -m pip install -r requirements.txt
          python3 -m pip install pytest

      - name: Run unit tests
        run: python3 -m pytest -q

  scrape-all:
    runs-on: self-hosted
    needs: test
    permissions:
      contents: read
    outputs:
      scrape_outcome: ${{ steps.scrape.outcome }}
    steps:
      - uses: actions/checkout@v4

      - name: Show Python version on self-hosted runner
        run: python3 --version

      - name: Install deps
        run: |
          python3 -m pip install -U pip
          python3 -m pip install -r requirements.txt

      - name: Run weekly scraping
        id: scrape
        continue-on-error: true
        env:
          GOOGLE_MAPS_API_KEY: ${{ secrets.GOOGLE_MAPS_API_KEY }}
          GOOGLE_PLACES_API_KEY: ${{ secrets.GOOGLE_PLACES_API_KEY }}
          TRIPADVISOR_API_KEY: ${{ secrets.TRIPADVISOR_API_KEY }}
        run: |
          python3 -m src.run --summary-json data/run_summary.json

      - name: Upload run summary
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: run-summary
          path: data/run_summary.json
          if-no-files-found: warn

  commit-data:
    if: always()
    runs-on: self-hosted
    needs: scrape-all
    permissions:
      contents: write
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Download run summary
        if: always()
        continue-on-error: true
        uses: actions/download-artifact@v4
        with:
          name: run-summary
          path: data

      - name: Commit updated CSV files
        run: |
          if git diff --quiet -- data/*.csv; then
            echo "No CSV changes to commit."
            exit 0
          fi

          git config user.name "github-actions[bot]"
          git config user.email "41898282+github-actions[bot]@users.noreply.github.com"
          git add data/*.csv
          git commit -m "chore(data): weekly score update $(date -u +%F)"
          git push

      - name: Mark workflow failed if scraping failed
        if: needs['scrape-all'].outputs.scrape_outcome == 'failure'
        run: |
          echo "One or more scrapers failed. Partial CSV updates were still committed."
          exit 1
