name: Weekly Reputation Update

on:
  schedule:
    - cron: "0 6 * * 1" # Mondays 06:00 UTC
  workflow_dispatch:

jobs:
  test:
    runs-on: ubuntu-latest
    permissions:
      contents: read
    steps:
      - uses: actions/checkout@v4

      - uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install deps
        run: |
          python -m pip install -U pip
          pip install -r requirements.txt
          pip install pytest

      - name: Run unit tests
        run: pytest -q

  scrape-nonexpedia:
    runs-on: ubuntu-latest
    needs: test
    permissions:
      contents: read
    outputs:
      scrape_outcome: ${{ steps.scrape_nonexpedia.outcome }}
    steps:
      - uses: actions/checkout@v4

      - uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install deps
        run: |
          python -m pip install -U pip
          pip install -r requirements.txt

      - name: Run non-Expedia scraping
        id: scrape_nonexpedia
        continue-on-error: true
        env:
          GOOGLE_MAPS_API_KEY: ${{ secrets.GOOGLE_MAPS_API_KEY }}
          GOOGLE_PLACES_API_KEY: ${{ secrets.GOOGLE_PLACES_API_KEY }}
          TRIPADVISOR_API_KEY: ${{ secrets.TRIPADVISOR_API_KEY }}
        run: |
          python -m src.run \
            --sites BOOKING TRIPADVISOR GOOGLE HOLIDAYCHECK \
            --summary-json data/run_summary_nonexpedia.json

      - name: Upload non-Expedia summary
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: run-summary-nonexpedia
          path: data/run_summary_nonexpedia.json
          if-no-files-found: warn

      - name: Upload non-Expedia CSVs
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: csv-nonexpedia
          path: |
            data/booking_scores.csv
            data/tripadvisor_scores.csv
            data/google_scores.csv
            data/holidaycheck_scores.csv
          if-no-files-found: warn

  scrape-expedia:
    runs-on: self-hosted
    needs: test
    permissions:
      contents: read
    env:
      RUNNER_TOOL_CACHE: /Users/laurabquintas/actions-runner/_tool
      AGENT_TOOLSDIRECTORY: /Users/laurabquintas/actions-runner/_tool
    outputs:
      scrape_outcome: ${{ steps.scrape_expedia.outcome }}
    steps:
      - uses: actions/checkout@v4

      - name: Prepare local Python tool cache
        run: mkdir -p "$RUNNER_TOOL_CACHE"

      - uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install deps
        run: |
          python -m pip install -U pip
          pip install -r requirements.txt

      - name: Run Expedia scraping (self-hosted)
        id: scrape_expedia
        continue-on-error: true
        run: |
          python -m src.run --sites EXPEDIA --summary-json data/run_summary_expedia.json

      - name: Upload Expedia summary
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: run-summary-expedia
          path: data/run_summary_expedia.json
          if-no-files-found: warn

      - name: Upload Expedia CSV
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: csv-expedia
          path: data/expedia_scores.csv
          if-no-files-found: warn

  commit-data:
    if: always()
    runs-on: ubuntu-latest
    needs: [scrape-nonexpedia, scrape-expedia]
    permissions:
      contents: write
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Download non-Expedia CSV artifact
        continue-on-error: true
        uses: actions/download-artifact@v4
        with:
          name: csv-nonexpedia
          path: _artifacts/nonexpedia

      - name: Download Expedia CSV artifact
        continue-on-error: true
        uses: actions/download-artifact@v4
        with:
          name: csv-expedia
          path: _artifacts/expedia

      - name: Merge CSV artifacts into data/
        run: |
          mkdir -p data
          cp -f _artifacts/nonexpedia/*.csv data/ || true
          cp -f _artifacts/expedia/*.csv data/ || true

      - name: Download run summaries
        if: always()
        continue-on-error: true
        uses: actions/download-artifact@v4
        with:
          pattern: run-summary-*
          path: _artifacts/summaries
          merge-multiple: true

      - name: Upload combined summaries
        if: always()
        continue-on-error: true
        uses: actions/upload-artifact@v4
        with:
          name: run-summaries-combined
          path: _artifacts/summaries
          if-no-files-found: warn

      - name: Commit updated CSV files
        run: |
          if git diff --quiet -- data/*.csv; then
            echo "No CSV changes to commit."
            exit 0
          fi

          git config user.name "github-actions[bot]"
          git config user.email "41898282+github-actions[bot]@users.noreply.github.com"
          git add data/*.csv
          git commit -m "chore(data): weekly score update $(date -u +%F)"
          git push

      - name: Mark workflow failed if any scrape failed
        if: needs['scrape-nonexpedia'].outputs.scrape_outcome == 'failure' || needs['scrape-expedia'].outputs.scrape_outcome == 'failure'
        run: |
          echo "One or more scraper jobs failed. Partial CSV updates were still committed."
          exit 1
